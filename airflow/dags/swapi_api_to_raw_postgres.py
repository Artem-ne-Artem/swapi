from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.empty import EmptyOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook

from dotenv import load_dotenv
from datetime import datetime
import psycopg2
import requests
import logging
import os


logger = logging.getLogger(__name__)
load_dotenv()

BASE_URL = "https://swapi.dev/api/"
TABLES = ["people", "planets", "films", "species", "vehicles", "starships"]
DB_NAME = "swapi"


def get_connection(database=None):
    """Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Postgres."""
    return psycopg2.connect(
        host="postgres_db_dwh",
        port=5432,
        user=os.getenv("POSTGRES_DWH_USER"),
        password=os.getenv("POSTGRES_DWH_PASSWORD"),
        dbname=database or "postgres",
    )


def get_init_database_and_schemas():
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ğ‘Ğ” swapi Ğ¸ ÑÑ…ĞµĞ¼Ñ‹ raw/ods/cdm, ĞµÑĞ»Ğ¸ Ğ¾Ğ½Ğ¸ Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‚."""
    # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ÑÑ Ğº ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ğ¾Ğ¹ Ğ±Ğ°Ğ·Ğµ postgres
    conn = get_connection()
    conn.autocommit = True
    cur = conn.cursor()

    cur.execute(f"SELECT 1 FROM pg_database WHERE datname = '{DB_NAME}';")
    exists = cur.fetchone()
    if not exists:
        cur.execute(f"CREATE DATABASE {DB_NAME};")
        logger.info(f"ğŸª„ Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… {DB_NAME} ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°")
    else:
        logger.info(f"âœ… Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… {DB_NAME} ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚")

    cur.close()
    conn.close()

    # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ÑÑ Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¹ Ğ±Ğ°Ğ·Ğµ Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ ÑÑ…ĞµĞ¼Ñ‹
    conn = get_connection(DB_NAME)
    conn.autocommit = True
    cur = conn.cursor()

    for schema in ["raw", "ods", "cdm"]:
        if not exists:
            cur.execute(f"CREATE SCHEMA IF NOT EXISTS {schema};")
            logger.info(f"ğŸ—ï¸ Ğ¡Ñ…ĞµĞ¼Ğ° {schema} ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°")
        else:
            logger.info(f"ğŸ—ï¸ Ğ¡Ñ…ĞµĞ¼Ğ° {schema} ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚")

    cur.close()
    conn.close()


def get_truncate_all_tables():
    conn = get_connection(DB_NAME)
    cur = conn.cursor()

    for schema in ["raw", "ods", "cdm"]:
        for table in TABLES:
            full_table = f"{schema}.{table}"
            try:
                cur.execute(f"TRUNCATE TABLE {full_table} RESTART IDENTITY CASCADE;")
                logger.info(f"ğŸ§¹ Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° {full_table} Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ° ")
            except Exception as e:
                logger.warning(f"âš ï¸ Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° {full_table} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ¸Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")

    conn.commit()
    cur.close()
    conn.close()


def get_fetch_swapi_data(endpoint):
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ²ÑĞµ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ SWAPI."""
    url = f"{BASE_URL}{endpoint}/"
    results = []
    while url:
        logger.info(f"ğŸ“¡ Fetching: {url}")
        res = requests.get(url, timeout=20)
        res.raise_for_status()
        data = res.json()
        results.extend(data["results"])
        url = data.get("next")
    logger.info(f"âœ… {endpoint}: {len(results)} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾")
    return results


def get_create_table_and_load_data(endpoint):
    """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ Ğ² raw Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· API."""
    conn = get_connection(DB_NAME)
    cur = conn.cursor()

    data = get_fetch_swapi_data(endpoint)
    if not data:
        logger.warning(f"âš ï¸ ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ {endpoint}")
        return

    sample = data[0]
    columns = [c for c in sample.keys() if isinstance(sample[c], (str, int, float, type(None)))]
    columns_sql = ", ".join([f'"{col}" TEXT' for col in columns])

    create_sql = f"""
        CREATE TABLE IF NOT EXISTS raw.{endpoint} (
            id SERIAL PRIMARY KEY,
            {columns_sql}
        );
    """
    cur.execute(create_sql)
    conn.commit()
    logger.info(f"ğŸ› ï¸ Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° raw.{endpoint} ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°")

    insert_sql = f"""
        INSERT INTO raw.{endpoint} ({', '.join(['"' + c + '"' for c in columns])})
        VALUES ({', '.join(['%s'] * len(columns))});
    """
    for item in data:
        values = [
            item.get(c) if isinstance(item.get(c), (str, int, float, type(None))) else str(item.get(c))
            for c in columns
        ]
        cur.execute(insert_sql, values)

    conn.commit()
    cur.close()
    conn.close()
    logger.info(f"ğŸš€ {endpoint}: Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½ ({len(data)} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹)")


with DAG(
    dag_id="api_to_raw_postgres",
    description="ĞŸÑ€Ğ¾ĞµĞºÑ‚ Swappi. Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ ÑÑ‹Ñ€Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· API Ğ² raw ÑĞ»Ğ¾Ğ¹ Ğ² Ğ‘Ğ” Postgres",
    start_date=datetime(2025, 11, 6),
    schedule_interval=None,
    catchup=False,
    tags=["swapi"],
) as dag:

    start = EmptyOperator(
        task_id="start"
    )

    init_db = PythonOperator(
        task_id="init_database_and_schemas",
        python_callable=get_init_database_and_schemas,
    )

    truncate_data = PythonOperator(
        task_id="truncate_all_tables",
        python_callable=get_truncate_all_tables,
    )

    import_people = PythonOperator(
        task_id="import_people",
        python_callable=get_create_table_and_load_data,
        op_args=["people"],
    )

    import_planets = PythonOperator(
        task_id="import_planets",
        python_callable=get_create_table_and_load_data,
        op_args=["planets"],
    )

    import_films = PythonOperator(
        task_id="import_films",
        python_callable=get_create_table_and_load_data,
        op_args=["films"],
    )

    import_species = PythonOperator(
        task_id="import_species",
        python_callable=get_create_table_and_load_data,
        op_args=["species"],
    )

    import_vehicles = PythonOperator(
        task_id="import_vehicles",
        python_callable=get_create_table_and_load_data,
        op_args=["vehicles"],
    )

    import_starships = PythonOperator(
        task_id="import_starships",
        python_callable=get_create_table_and_load_data,
        op_args=["starships"],
    )

    end = EmptyOperator(
        task_id="end"
    )

    start >> init_db >> truncate_data >> import_people >> import_planets >> import_films >> import_species >> import_vehicles >> import_starships >> end