from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.empty import EmptyOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from datetime import datetime
import requests
import logging

logger = logging.getLogger(__name__)

TABLES = ["people", "planets", "films", "species", "vehicles", "starships"]
BASE_URL = "https://swapi.dev/api/"


def truncate_all_tables():
    """
    1ï¸âƒ£ ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ÑÑ Ğº Postgres
    2ï¸âƒ£ Ğ¢Ñ€Ğ°Ğ½ĞºĞµĞ¹Ñ‚Ğ¸ Ğ²ÑĞµÑ… Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ† Ğ¸Ğ· ÑĞ¿Ğ¸ÑĞºĞ° TABLES Ğ²Ğ¾ Ğ²ÑĞµÑ… ÑÑ…ĞµĞ¼Ğ°Ñ…
    """
    hook = PostgresHook(postgres_conn_id="swapi_postgres")
    conn = hook.get_conn()
    cur = conn.cursor()

    for schema in ["raw", "ods", "cdm"]:
        for table in TABLES:
            full_table = f"{schema}.{table}"
            try:
                cur.execute(f"TRUNCATE TABLE {full_table} RESTART IDENTITY CASCADE;")
                logger.info(f"ğŸ§¹ Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° {full_table} Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ° ")
            except Exception as e:
                logger.warning(f"âš ï¸ Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° {full_table} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ¸Ğ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {e}")

    conn.commit()
    cur.close()
    conn.close()


def fetch_swapi_data(endpoint):
    """Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ²ÑĞµ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹ SWAPI."""
    url = f"{BASE_URL}{endpoint}/"
    results = []
    while url:
        logger.info(f"ğŸ“¡ Fetching: {url}")
        res = requests.get(url, timeout=20)
        res.raise_for_status()
        data = res.json()
        results.extend(data["results"])
        url = data.get("next")
    logger.info(f"âœ… {endpoint}: {len(results)} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾")
    return results


def create_table_and_load_data(endpoint):
    """
    Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ:
    1. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñƒ (Ğ² ÑÑ…ĞµĞ¼Ğµ raw)
    2. Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· SWAPI
    3. Ğ’ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑÑ‚Ñ€Ğ¾ĞºĞ¸
    """
    hook = PostgresHook(postgres_conn_id="swapi_postgres")
    conn = hook.get_conn()
    cur = conn.cursor()

    data = fetch_swapi_data(endpoint)
    if not data:
        logger.warning(f"âš ï¸ ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ {endpoint}")
        return

    sample = data[0]
    columns = [c for c in sample.keys() if isinstance(sample[c], (str, int, float, type(None)))]
    columns_sql = ", ".join([f'"{col}" TEXT' for col in columns])

    create_sql = f"""
        CREATE TABLE IF NOT EXISTS raw.{endpoint} (
            id SERIAL PRIMARY KEY,
            {columns_sql}
        );
    """
    cur.execute(create_sql)
    conn.commit()
    logger.info(f"ğŸ› ï¸ Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° raw.{endpoint} ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ°")

    insert_sql = f"""
        INSERT INTO raw.{endpoint} ({', '.join(['"' + c + '"' for c in columns])})
        VALUES ({', '.join(['%s'] * len(columns))});
    """
    for item in data:
        values = [
            item.get(c) if isinstance(item.get(c), (str, int, float, type(None))) else str(item.get(c))
            for c in columns
        ]
        cur.execute(insert_sql, values)

    conn.commit()
    cur.close()
    conn.close()
    logger.info(f"ğŸš€ {endpoint}: Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½ ({len(data)} Ğ·Ğ°Ğ¿Ğ¸ÑĞµĞ¹)")


with DAG(
    dag_id="api_to_raw_postgres",
    description="ĞŸÑ€Ğ¾ĞµĞºÑ‚ Swappi. Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚ ÑÑ‹Ñ€Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· API Ğ² raw ÑĞ»Ğ¾Ğ¹ Ğ² Ğ‘Ğ” Postgres",
    start_date=datetime(2025, 11, 6),
    schedule_interval=None,
    catchup=False,
    tags=["swapi"],
) as dag:

    start = EmptyOperator(
        task_id="start"
    )

    truncate_data = PythonOperator(
        task_id="truncate_all_tables",
        python_callable=truncate_all_tables,
    )

    # import_data = []
    # for table in TABLES:
    #     task = PythonOperator(
    #         task_id=f"import_{table}",
    #         python_callable=create_table_and_load_data,
    #         op_args=[table],
    #     )
    #     import_data.append(task)

    import_people = PythonOperator(
        task_id="import_people",
        python_callable=create_table_and_load_data,
        op_args=["people"],
    )

    import_planets = PythonOperator(
        task_id="import_planets",
        python_callable=create_table_and_load_data,
        op_args=["planets"],
    )

    import_films = PythonOperator(
        task_id="import_films",
        python_callable=create_table_and_load_data,
        op_args=["films"],
    )

    import_species = PythonOperator(
        task_id="import_species",
        python_callable=create_table_and_load_data,
        op_args=["species"],
    )

    import_vehicles = PythonOperator(
        task_id="import_vehicles",
        python_callable=create_table_and_load_data,
        op_args=["vehicles"],
    )

    import_starships = PythonOperator(
        task_id="import_starships",
        python_callable=create_table_and_load_data,
        op_args=["starships"],
    )

    end = EmptyOperator(
        task_id="end"
    )

    start >> truncate_data >> import_people >> import_planets >> import_films >> import_species >> import_vehicles >> import_starships >> end